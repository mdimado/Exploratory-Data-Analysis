# Exploratory Data Analysis (EDA) Learning Journey

This repository is my learning playground for mastering **Exploratory Data Analysis (EDA)**. It documents my progress, experiments, and insights as I dive deep into the world of data.

## What is EDA?

EDA is a form of a step/approach which is used to analyze datasets so that we can get some insights out of it (visuals) and to obtain confidence in a data to an extent where we are ready to engage a machine learning model.

EDA helps us in finding the errors, dscovering data, mapping out data structure and finding out anomalies

---

## Visualization
visualization is the presentation of the data in the graphical or visual form to understand the data more clearly.
- Easily understand the features of the data
- Easily analyze the data and summarize it
- Help to get meaningful insights from the data
- Help to find the trend or pattern of the data

---

## Steps involved in EDA
### 1. Data Sourcing:
- The process of gathering data from multiple sources as external or internal data collection
     There are two major kind of data which can be classified according to the source:
     1. **Public data:** Easily accessible, data made public for the purpose of research
     2. **Private data:** Data which is not available on public platform

### 2. Data Cleaning:
- The process of cleaning the data to improve the quality of the data for further data analysis and building a machine learning model. The benifit of data cleaning is that all irrelevent data is gone, and we get the good quality of data which will help in improving the accuracy of our ML model.
    - Handling missing values
    - Standardization of the data
    - Outlier treatment
    - Handle invalid values

#### Handling missing values
- Delete rows/columns: commonly used to handle missing values. Rows can be deleted if it has insignificant number of missing values. Columns can be deleted if it has more than 75% of missing values (no thumb rule)
- Replacing with mean/median/mode: can be used on independent numerical variables. categorical features can be imputed with mode.
- Algorithm imputation: Some ML algorithm supports to handle missing values in the dataset. Like KNN, Naive Bayes, Random forest.
- Predicting the missing values: 
---

## Topics Covered
- *(No topics covered yet. Stay tuned!)*

---

## Topics Not Yet Covered
- **Data Collection & Loading**: Gather and load data from various sources.
- **Data Cleaning**: Handle missing values and duplicates effectively.
- **Data Transformation**: Normalize, encode, and transform data for analysis.
- **Data Visualization**: Create visualizations to spot trends and patterns.
- **Descriptive Statistics**: Summarize data using measures like mean, median, etc.
- **Detecting Patterns**: Identify relationships and emerging trends.
- **Handling Outliers**: Methods to identify and address outliers.
- **Correlation Analysis**: Explore feature dependencies and relationships.
- **Initial Modeling**: Experiment with simple models and hypotheses.

---

Feel free to explore, experiment, and learn! ðŸ˜Š


